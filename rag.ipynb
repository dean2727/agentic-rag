{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview of this notebook\n",
    "\n",
    "In this, we explore the notion of agentic RAG using DeepSeek.\n",
    "\n",
    "Agentic RAG is an RAG that integrates the capabilities of Agent, and the core capabilities of Agent are autonomous reasoning and action.\n",
    "\n",
    "Therefore, Agentic RAG brings the autonomous planning capabilities of AI agents (such as routing, action steps, reflection, etc.) into traditional RAG to adapt to more complex RAG query tasks.\n",
    "\n",
    "Agentic RAG's **“agent”** feature is mainly reflected in the retrieval stage. Compared to the retrieval process in traditional RAG, Agentic RAG is more capable of:\n",
    "\n",
    "- Deciding whether to search (autonomous decision-making)\n",
    "- Choosing which search engine to use (autonomous planning)\n",
    "- Evaluating the retrieved context and deciding whether to re-search (self-planning)\n",
    "- Determining whether to use external tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install streamlit chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.messages import HumanMessage, AIMessage, ToolMessage\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.graph.message import add_messages\n",
    "from typing_extensions import TypedDict, Annotated\n",
    "from typing import Sequence\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "import re\n",
    "import os\n",
    "import streamlit as st\n",
    "import requests\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "import chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv('.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "deepseek_api_key = os.getenv(\"DEEPSEEK_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dummy Data\n",
    "research_texts = [\n",
    "    \"Research Report: Results of a New AI Model Improving Image Recognition Accuracy to 98%\",\n",
    "    \"Academic Paper Summary: Why Transformers Became the Mainstream Architecture in Natural Language Processing\",\n",
    "    \"Latest Trends in Machine Learning Methods Using Quantum Computing\"\n",
    "]\n",
    "\n",
    "development_texts = [\n",
    "    \"Project A: UI Design Completed, API Integration in Progress\",\n",
    "    \"Project B: Testing New Feature X, Bug Fixes Needed\",\n",
    "    \"Product Y: In the Performance Optimization Stage Before Release\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s process the data by splitting it into smaller parts, converting it into document objects, and then creating vector embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a retriever of type BaseRetriever, from the dummy data\n",
    "def create_retriever(texts):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=0)\n",
    "    docs = text_splitter.create_documents(texts)\n",
    "    return Chroma.from_documents(docs, OpenAIEmbeddings()).as_retriever()\n",
    "\n",
    "research_retriever = create_retriever(research_texts)\n",
    "development_retriever = create_retriever(development_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "research_tool = create_retriever_tool(\n",
    "    research_retriever,  # Retriever object\n",
    "    \"research_db_tool\",  # Name of the tool to create\n",
    "    \"Search information from the research database.\"  # Description of the tool\n",
    ")\n",
    "\n",
    "development_tool = create_retriever_tool(\n",
    "    development_retriever,\n",
    "    \"development_db_tool\",\n",
    "    \"Search information from the development database.\"\n",
    ")\n",
    "\n",
    "# Combine the created research and development tools into a list\n",
    "tools = [research_tool, development_tool]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The documents retrieved by this tool can be extracted from the return value of the function that this tool wraps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will be used in multiple steps of the graph\n",
    "def call_deepseek(prompt: str):\n",
    "    headers = {\n",
    "        \"Accept\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {deepseek_api_key}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    \n",
    "    data = {\n",
    "        \"model\": \"deepseek-chat\",\n",
    "        \"messages\": [{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt\n",
    "        }],\n",
    "        \"temperature\": 0.7,\n",
    "        \"max_tokens\": 1024\n",
    "    }\n",
    "    \n",
    "    response = requests.post(\n",
    "        \"https://api.deepseek.com/v1/chat/completions\",\n",
    "        headers=headers,\n",
    "        json=data,\n",
    "        verify=False\n",
    "    )\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can implement an agent as a router for queries. Using a prompt, we can categorize the query as research or development related. We can connect to DeepSeek with temperature of 0.7 for balanced responses, and when the API responds, check if it’s a research or development query, then use the appropriate retriever to find relevant documents. If it doesnt fit either query, return a direct answer. This agent can be thought of as a traffic controller, to route to the right data source for queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[AIMessage|HumanMessage|ToolMessage], add_messages]\n",
    "\n",
    "def traffice_router_agent(state: AgentState):\n",
    "    print(\"---CALL AGENT---\")\n",
    "    messages = state[\"messages\"]\n",
    "\n",
    "    if isinstance(messages[0], tuple):\n",
    "        user_message = messages[0][1]\n",
    "    else:\n",
    "        user_message = messages[0].content\n",
    "\n",
    "    # Structure prompt for consistent text output\n",
    "    prompt = f\"\"\"Given this user question: \"{user_message}\"\n",
    "    If it's about research or academic topics, respond EXACTLY in this format:\n",
    "    SEARCH_RESEARCH: <search terms>\n",
    "    \n",
    "    If it's about development status, respond EXACTLY in this format:\n",
    "    SEARCH_DEV: <search terms>\n",
    "    \n",
    "    Otherwise, just answer directly.\n",
    "    \"\"\"\n",
    "\n",
    "    response = call_deepseek(prompt)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        response_text = response.json()['choices'][0]['message']['content']\n",
    "        print(\"Raw response:\", response_text)\n",
    "        \n",
    "        # Format the response into expected tool format\n",
    "        if \"SEARCH_RESEARCH:\" in response_text:\n",
    "            query = response_text.split(\"SEARCH_RESEARCH:\")[1].strip()\n",
    "            # Use direct call to research retriever\n",
    "            results = research_retriever.invoke(query)\n",
    "            return {\"messages\": [AIMessage(content=f'Action: research_db_tool\\n{{\"query\": \"{query}\"}}\\n\\nResults: {str(results)}')]}\n",
    "        elif \"SEARCH_DEV:\" in response_text:\n",
    "            query = response_text.split(\"SEARCH_DEV:\")[1].strip()\n",
    "            # Use direct call to development retriever\n",
    "            results = development_retriever.invoke(query)\n",
    "            return {\"messages\": [AIMessage(content=f'Action: development_db_tool\\n{{\"query\": \"{query}\"}}\\n\\nResults: {str(results)}')]}\n",
    "        else:\n",
    "            return {\"messages\": [AIMessage(content=response_text)]}\n",
    "    else:\n",
    "        raise Exception(f\"API call failed: {response.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for a grading function, which will check if there are documents in the result. If there are, move forward to an answer. If not, suggest rewriting the query for better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_grade_documents(state: AgentState):\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    print(\"Evaluating message:\", last_message.content)\n",
    "    \n",
    "    # Check if the content contains retrieved documents\n",
    "    if \"Results: [Document\" in last_message.content:\n",
    "        print(\"---DOCS FOUND, GO TO GENERATE---\")\n",
    "        return \"generate\"\n",
    "    else:\n",
    "        print(\"---NO DOCS FOUND, TRY REWRITE---\")\n",
    "        return \"rewrite\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rewrite(state: AgentState):\n",
    "    print(\"---REWRITE QUESTION---\")\n",
    "    messages = state[\"messages\"]\n",
    "    original_question = messages[0].content if len(messages)>0 else \"N/A\"\n",
    "\n",
    "    response = call_deepseek(f\"Rewrite this question to be more specific and clearer: {original_question}\")\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        response_text = response.json()['choices'][0]['message']['content']\n",
    "        print(\"Rewritten question:\", response_text)\n",
    "        return {\"messages\": [AIMessage(content=response_text)]}\n",
    "    else:\n",
    "        raise Exception(f\"API call failed: {response.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the generate final answer function. We can use DeepSeek to generate the final answer for us based on the found documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(state: AgentState):\n",
    "    print(\"---GENERATE FINAL ANSWER---\")\n",
    "    messages = state[\"messages\"]\n",
    "    question = messages[0].content if isinstance(messages[0], tuple) else messages[0].content\n",
    "    last_message = messages[-1]\n",
    "\n",
    "    # Extract the document content from the results\n",
    "    docs = \"\"\n",
    "    if \"Results: [\" in last_message.content:\n",
    "        results_start = last_message.content.find(\"Results: [\")\n",
    "        docs = last_message.content[results_start:]\n",
    "    print(\"Documents found:\", docs)\n",
    "\n",
    "    \n",
    "    prompt = f\"\"\"Based on these research documents, summarize the latest advancements in AI:\n",
    "    Question: {question}\n",
    "    Documents: {docs}\n",
    "    Focus on extracting and synthesizing the key findings from the research papers.\n",
    "    \"\"\"\n",
    "\n",
    "    response = call_deepseek(prompt)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        response_text = response.json()['choices'][0]['message']['content']\n",
    "        print(\"Final Answer:\", response_text)\n",
    "        return {\"messages\": [AIMessage(content=response_text)]}\n",
    "    else:\n",
    "        raise Exception(f\"API call failed: {response.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets create a decision-making function that checks if we need to use any tools based on the message content. Lets look at the last message and check if it matches our tool pattern (which looks for “Action:” at the start). If it matches, signal that we should retrieve information using our tools. If it doesn’t match, signal that we should end the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools_pattern = re.compile(r\"Action: .*\")\n",
    "\n",
    "def custom_tools_condition(state: AgentState):\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    content = last_message.content\n",
    "\n",
    "    print(\"Checking tools condition:\", content)\n",
    "    if tools_pattern.match(content):\n",
    "        print(\"Moving to retrieve...\")\n",
    "        return \"tools\"\n",
    "    print(\"Moving to END...\")\n",
    "    return END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "workflow.add_node(\"traffic_router_agent\", traffice_router_agent)\n",
    "retrieve_node = ToolNode(tools)\n",
    "workflow.add_node(\"retrieve\", retrieve_node)\n",
    "workflow.add_node(\"rewrite\", rewrite)\n",
    "workflow.add_node(\"generate\", generate)\n",
    "\n",
    "workflow.add_edge(START, \"traffic_router_agent\")\n",
    "\n",
    "# If the agent calls a tool, proceed to retrieve; otherwise, go to END\n",
    "workflow.add_conditional_edges(\n",
    "    \"traffic_router_agent\",\n",
    "    custom_tools_condition,\n",
    "    {\n",
    "        \"tools\": \"retrieve\",\n",
    "        END: END\n",
    "    }\n",
    ")\n",
    "\n",
    "# After retrieve, determine whether to generate or rewrite\n",
    "workflow.add_conditional_edges(\"retrieve\", simple_grade_documents)\n",
    "workflow.add_edge(\"generate\", END)\n",
    "workflow.add_edge(\"rewrite\", \"traffic_router_agent\")\n",
    "\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_question(user_question, config):\n",
    "    \"\"\"Process user question through the workflow\"\"\"\n",
    "    events = []\n",
    "    for event in app.stream({\"messages\":[(\"user\", user_question)]}, config):\n",
    "        events.append(event)\n",
    "    return events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CALL AGENT---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/deanorenstein/opt/anaconda3/envs/oai/lib/python3.12/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.deepseek.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw response: SEARCH_RESEARCH: latest advancements in AI research 2023\n",
      "Checking tools condition: Action: research_db_tool\n",
      "{\"query\": \"latest advancements in AI research 2023\"}\n",
      "\n",
      "Results: [Document(metadata={}, page_content='Latest Trends in Machine Learning Methods Using Quantum Computing'), Document(metadata={}, page_content='Research Report: Results of a New AI Model Improving Image Recognition Accuracy to 98%'), Document(metadata={}, page_content='Project A: UI Design Completed, API Integration in Progress'), Document(metadata={}, page_content='Academic Paper Summary: Why Transformers Became the Mainstream Architecture in Natural Language')]\n",
      "Moving to retrieve...\n",
      "Evaluating message: Action: research_db_tool\n",
      "{\"query\": \"latest advancements in AI research 2023\"}\n",
      "\n",
      "Results: [Document(metadata={}, page_content='Latest Trends in Machine Learning Methods Using Quantum Computing'), Document(metadata={}, page_content='Research Report: Results of a New AI Model Improving Image Recognition Accuracy to 98%'), Document(metadata={}, page_content='Project A: UI Design Completed, API Integration in Progress'), Document(metadata={}, page_content='Academic Paper Summary: Why Transformers Became the Mainstream Architecture in Natural Language')]\n",
      "---DOCS FOUND, GO TO GENERATE---\n",
      "---GENERATE FINAL ANSWER---\n",
      "Documents found: Results: [Document(metadata={}, page_content='Latest Trends in Machine Learning Methods Using Quantum Computing'), Document(metadata={}, page_content='Research Report: Results of a New AI Model Improving Image Recognition Accuracy to 98%'), Document(metadata={}, page_content='Project A: UI Design Completed, API Integration in Progress'), Document(metadata={}, page_content='Academic Paper Summary: Why Transformers Became the Mainstream Architecture in Natural Language')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/deanorenstein/opt/anaconda3/envs/oai/lib/python3.12/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.deepseek.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Answer: Based on the provided research documents, the latest advancements in AI research can be summarized as follows:\n",
      "\n",
      "1. **Quantum Computing in Machine Learning**:  \n",
      "   One of the latest trends involves the integration of quantum computing with machine learning methods. This approach aims to leverage the computational power of quantum systems to solve complex problems more efficiently than classical computing methods. Quantum computing is expected to enhance the speed and scalability of AI models, particularly in areas requiring massive data processing and optimization.\n",
      "\n",
      "2. **Improved Image Recognition Accuracy**:  \n",
      "   A significant breakthrough has been achieved in image recognition, with a new AI model achieving **98% accuracy**. This advancement demonstrates the potential for AI to perform highly precise visual tasks, which could have applications in fields such as medical imaging, autonomous vehicles, and security systems. The research highlights the importance of refining model architectures and training techniques to push the boundaries of accuracy.\n",
      "\n",
      "3. **Transformers in Natural Language Processing (NLP)**:  \n",
      "   Transformers have solidified their position as the mainstream architecture in NLP. The academic paper emphasizes their ability to handle long-range dependencies and contextual understanding, making them highly effective for tasks like language translation, text generation, and sentiment analysis. This architecture's success has led to the development of advanced models like GPT and BERT, which continue to dominate the NLP landscape.\n",
      "\n",
      "4. **UI Design and API Integration**:  \n",
      "   While not directly related to AI model advancements, the progress in **Project A** highlights the importance of user interface (UI) design and API integration in deploying AI systems. This indicates a growing focus on making AI technologies more accessible and user-friendly, ensuring seamless integration into real-world applications.\n",
      "\n",
      "In summary, the latest advancements in AI research include the integration of quantum computing, breakthroughs in image recognition accuracy, the dominance of transformer architectures in NLP, and the emphasis on practical deployment through UI and API development. These developments collectively push the boundaries of AI capabilities and usability.\n"
     ]
    }
   ],
   "source": [
    "q = \"What is the latest advancement in AI research?\"\n",
    "events = process_question(q, {\"configurable\":{\"thread_id\":\"1\"}})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
